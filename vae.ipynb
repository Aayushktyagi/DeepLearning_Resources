{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "vae_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayushktyagi/DeepLearning_Resources/blob/master/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzyZ2Yx1ZfdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from skimage.transform import rescale, resize\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5q282hZZfdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVkwXagzZfdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "# KERAS IMPORTS\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.layers import concatenate, add\n",
        "# from tensorflow.keras.models import Sequential, Model\n",
        "# from tensorflow.keras.layers import Input\n",
        "# from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.layers import Conv2D\n",
        "# from tensorflow.keras.layers import Conv2DTranspose\n",
        "# from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
        "# from tensorflow.keras.layers import UpSampling2D\n",
        "# # from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
        "# from tensorflow.keras.layers import LeakyReLU\n",
        "# from tensorflow.keras.layers import Activation\n",
        "# from tensorflow.keras.layers import BatchNormalization\n",
        "# from tensorflow.keras.layers import Lambda\n",
        "# from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
        "# from tensorflow.keras.layers import Flatten\n",
        "# from tensorflow.keras.layers import Reshape\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# from tensorflow.keras.layers import Add, Multiply\n",
        "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "# from tensorflow.keras.losses import mse, binary_crossentropy\n",
        "\n",
        "# import tensorflow.keras.backend as K\n",
        "# from tensorflow.keras.utils import multi_gpu_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import concatenate, add\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import MaxPool2D, AvgPool2D\n",
        "from keras.layers import UpSampling2D\n",
        "# from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Reshape\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Add, Multiply\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras import initializers\n",
        "import keras.backend as K\n",
        "from keras.utils import multi_gpu_model\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfY_S0TxZfd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set some parameters\n",
        "im_width = 128\n",
        "im_height = 128\n",
        "n_channels = 3\n",
        "border = 5\n",
        "n_filters=8\n",
        "dropout=0.05\n",
        "batchnorm=True\n",
        "path_train = './Dataset/Compaq_orignal/Compaq_orignal/Compaq_orignal/train/'\n",
        "path_valid = './Dataset/Compaq_orignal/Compaq_orignal/Compaq_orignal/test/'\n",
        "path_test = './Dataset/Compaq_orignal/test_NIR/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqzM8VYtZfeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "def get_data(train_data_path):\n",
        "    img_size = 128\n",
        "#     train_ids = next(os.walk(train_data_path))[1]\n",
        "    train_ids = next(os.walk(train_data_path + \"image/1\"))[2]\n",
        "    x_train = []\n",
        "#     x_train = np.zeros((len(train_ids), img_size, img_size, 3), dtype=np.uint8)\n",
        "    y_train = np.zeros((len(train_ids), img_size, img_size, 1), dtype=np.bool)\n",
        "\n",
        "    for i, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
        "        path = train_data_path+\"image/1\"+\"/{}\".format(id_)\n",
        "        img = cv2.imread(path,1)\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        img = np.asarray(img) / 127.5\n",
        "        img = img - 1\n",
        "        x_train.append(img)\n",
        "\n",
        "        height, width, _ = img.shape\n",
        "        label = np.zeros((height, width, 1))\n",
        "        path2 = train_data_path+\"label/1/\"\n",
        "        mask_ = cv2.imread(path2+id_, 0)\n",
        "        mask_ = cv2.resize(mask_, (img_size, img_size))\n",
        "        mask_ = np.expand_dims(mask_, axis=-1)\n",
        "        label = np.maximum(label, mask_)\n",
        "        y_train[i]=label\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.asarray(y_train).astype(np.uint8)\n",
        "    return x_train , y_train\n",
        "X_train, y_train = get_data(path_train)\n",
        "X_valid , y_valid = get_data(path_valid)\n",
        "X_test , y_test = get_data(path_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EReUGAQbZfeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if training data looks all right\n",
        "ix = random.randint(0, len(X_train))\n",
        "has_mask = y_train[ix].max() > 0\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "# image = X_train[ix, ... , 0]\n",
        "image = X_train[ix,:,:,:].reshape(128,128,3)\n",
        "# image = (image + 1 ) / 2\n",
        "# image = image * 255\n",
        "ax[0].imshow(image.astype('uint8'))\n",
        "if has_mask:\n",
        "    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\n",
        "ax[0].set_title('Image')\n",
        "\n",
        "ax[1].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\n",
        "ax[1].set_title('Mask');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40FN0l_MZfeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SET A SEED FOR REPRODUCABILITY\n",
        "np.random.seed(20)\n",
        "\n",
        "#NUMBER OF DIMENSIONS IN THE ENCODED LAYER\n",
        "latent_dims = 64\n",
        "image_size = 128\n",
        "n_channel = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LeQl0_9ZfeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def edge_comp(image):\n",
        "    edge = tf.image.sobel_edges(image)\n",
        "    edge = concatenate([edge[:,:,:,:,0],edge[:,:,:,:,1]],axis = -1)\n",
        "    print(edge.shape)\n",
        "    return edge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZgmUQ8-Zfeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ENCODER\n",
        "#BUILT WITH FUNCTIONAL MODEL DUE TO THE MULTIPLE INPUTS AND OUTPUTS\n",
        "\n",
        "encoder_in = Input(shape=(image_size,image_size,n_channel),name = 'encoder_input')   ##INPUT FOR THE IMAGE\n",
        "\n",
        "input_edge = Lambda(edge_comp)(encoder_in)\n",
        "\n",
        "encoder_l1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', input_shape=(image_size,image_size,n_channel),kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_in)\n",
        "# encoder_l1 = BatchNormalization()(encoder_l1)\n",
        "encoder_l1 = Activation(LeakyReLU(0.2))(encoder_l1)\n",
        "\n",
        "encoder_l1 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_l1)\n",
        "# encoder_l1 = BatchNormalization()(encoder_l1)\n",
        "encoder_l1 = Activation(LeakyReLU(0.2))(encoder_l1)\n",
        "\n",
        "\n",
        "encoder_l2 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_l1)\n",
        "# encoder_l2 = BatchNormalization()(encoder_l2)\n",
        "encoder_l2 = Activation(LeakyReLU(0.2))(encoder_l2)\n",
        "\n",
        "encoder_l3 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_l2)\n",
        "# encoder_l3 = BatchNormalization()(encoder_l3)\n",
        "encoder_l3 = Activation(LeakyReLU(0.2))(encoder_l3)\n",
        "\n",
        "\n",
        "encoder_l4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_l3)\n",
        "# encoder_l4 = BatchNormalization()(encoder_l4)\n",
        "encoder_l4 = Activation(LeakyReLU(0.2))(encoder_l4)\n",
        "\n",
        "encoder_l5 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_l4)\n",
        "# encoder_l4 = BatchNormalization()(encoder_l4)\n",
        "encoder_l5 = Activation(LeakyReLU(0.2))(encoder_l5)\n",
        "\n",
        "flatten = Flatten()(encoder_l5)\n",
        "\n",
        "encoder_dense = Dense(1024,kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(flatten)\n",
        "# encoder_dense = BatchNormalization()(encoder_dense)\n",
        "encoder_out = Activation(LeakyReLU(0.2))(encoder_dense)\n",
        "\n",
        "\n",
        "mu = Dense(latent_dims,kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_out)\n",
        "log_var = Dense(latent_dims,kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(encoder_out)\n",
        "\n",
        "\n",
        "epsilon = Input(tensor=K.random_normal(shape=(K.shape(mu)[0], latent_dims)))  ##INPUT EPSILON FOR RANDOM SAMPLING\n",
        "\n",
        "sigma = Lambda(lambda x: K.exp(0.5 * x))(log_var) # CHANGE log_var INTO STANDARD DEVIATION(sigma)\n",
        "z_eps = Multiply()([sigma, epsilon])\n",
        "\n",
        "z = Add()([mu, z_eps])\n",
        "\n",
        "encoder=Model(inputs = [encoder_in,epsilon], outputs =[z,input_edge],name='encoder')\n",
        "print(encoder.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d69wRco3Zfeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DECODER\n",
        "# # layer 1\n",
        "decoder_in = Input(shape=(latent_dims,),name='decoder_input')\n",
        "decoder_edge = Input(shape = (image_size,image_size,6),name = 'edge_input')\n",
        "decoder_l1 = Dense(1024, input_shape=(latent_dims,),kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_in)\n",
        "# decoder_l1 = BatchNormalization()(decoder_l1)\n",
        "decoder_l1 = Activation(LeakyReLU(0.2))(decoder_l1)\n",
        "#layer 2\n",
        "decoder_l2 = Dense(2048,kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l1)\n",
        "# decoder_l2 = BatchNormalization()(decoder_l2)\n",
        "decoder_l2 = Activation(LeakyReLU(0.2))(decoder_l2)\n",
        "#reshape \n",
        "decoder_reshape = Reshape(target_shape=(4,4,128))(decoder_l2)\n",
        "# layer 3\n",
        "decoder_l3 = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_reshape)\n",
        "# decoder_l3 = BatchNormalization()(decoder_l3)\n",
        "decoder_l3 = Activation(LeakyReLU(0.2))(decoder_l3)\n",
        "#layer 4 \n",
        "decoder_l4 = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l3)\n",
        "# decoder_l4 = BatchNormalization()(decoder_l4)\n",
        "decoder_l4 = Activation(LeakyReLU(0.2))(decoder_l4)\n",
        "#layer 5 \n",
        "decoder_l5 = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l4)\n",
        "# decoder_l5 = BatchNormalization()(decoder_l5)\n",
        "decoder_l5 = Activation(LeakyReLU(0.2))(decoder_l5)\n",
        "#layer 6\n",
        "decoder_l6 = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l5)\n",
        "# decoder_l6 = BatchNormalization()(decoder_l6)\n",
        "decoder_l6 = Activation(LeakyReLU(0.2))(decoder_l6)\n",
        "#layer 7\n",
        "# decoder_l7 = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l6)\n",
        "# # decoder_l7 = BatchNormalization()(decoder_l7)\n",
        "# decoder_l7 = Activation(LeakyReLU(0.2))(decoder_l7)\n",
        "#layer 8\n",
        "decoder_l8 = Conv2DTranspose(filters=3, kernel_size=3, strides=2, padding='same',kernel_initializer = initializers.RandomNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l6)\n",
        "# decoder_l8 = BatchNormalization()(decoder_l8)\n",
        "# decoder_l8 = Activation(LeakyReLU(0.2))(decoder_l8)\n",
        "decoder_l8 = Activation('tanh')(decoder_l8)\n",
        "decoder_ledge = concatenate([decoder_l8,decoder_edge],axis = -1)\n",
        "\n",
        "#layer 9\n",
        "decoder_l9 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_ledge)\n",
        "# decoder_l9 = BatchNormalization()(decoder_l9)\n",
        "decoder_l9 = Activation(LeakyReLU(0.2))(decoder_l9)\n",
        "\n",
        "decoder_l10 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l9)\n",
        "# decoder_l9 = BatchNormalization()(decoder_l9)\n",
        "decoder_l10 = Activation(LeakyReLU(0.2))(decoder_l10)\n",
        "\n",
        "decoder_l11 = Conv2D(filters=3, kernel_size=3, strides=1, padding='same',kernel_initializer = initializers.TruncatedNormal(stddev=0.02),bias_initializer=initializers.Constant(value=0.0))(decoder_l10)\n",
        "# decoder_l9 = BatchNormalization()(decoder_l9)\n",
        "decoder_out = Activation('tanh')(decoder_l11)\n",
        "\n",
        "decoder=Model(inputs = [decoder_in , decoder_edge],outputs = [decoder_out],name='vae_decoder')\n",
        "print(decoder.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IHoUlUJZfex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COMBINE ENCODER AND DECODER THE COMPLETE THE VARIATIONAL AUTO ENCODER\n",
        "encoder_out,edge_input = encoder([encoder_in,epsilon])\n",
        "decoder_out = decoder([encoder_out,edge_input])\n",
        "vae = Model([encoder_in, epsilon], decoder_out)\n",
        "vae = multi_gpu_model(vae, gpus=4)\n",
        "vae.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EegD_vB1Zfe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MY LOSS FUNCTIONS\n",
        "\n",
        "def reconstruction_loss(y_true, y_pred):\n",
        "    return K.mean(K.square(y_true - y_pred)) + K.mean(K.abs(y_true - y_pred))\n",
        "\n",
        "def kl_loss(y_true, y_pred):\n",
        "    kl_loss = - 0.5 * K.mean(1 + log_var - K.square(mu) - K.exp(log_var), axis=-1)\n",
        "    return kl_loss\n",
        "\n",
        "def vae_loss(y_true, y_pred):\n",
        "    return 10* reconstruction_loss(y_true, y_pred) +  1 * kl_loss(y_true, y_pred)   #scaling kl_loss by 0.03 seem to help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy6kBm8nZffC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.RMSprop(lr=0.0001 , decay=1e-3)\n",
        "vae.compile(optimizer=opt, loss=vae_loss , metrics=[reconstruction_loss,kl_loss])\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, verbose=1,monitor='val_loss'),\n",
        "    ReduceLROnPlateau(monitor = 'val_loss',factor=0.5, patience=3, min_lr=0.000001, verbose=1,mode='max',cooldown=2),\n",
        "    ModelCheckpoint('./vae_final_batch64.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PEm0rtjiZffK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=vae.fit(X_train,X_train,\n",
        "                epochs=150,\n",
        "                batch_size=64,\n",
        "                validation_data = (X_valid,X_valid),\n",
        "               callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxs3QhYkZffQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showloss(history):\n",
        "        # loss plot\n",
        "        plt.subplots(figsize=(15,10))\n",
        "        plt.subplot(1,1,1)\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['reconstruction_loss'])\n",
        "        plt.plot(history.history['kl_loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.plot(history.history['val_reconstruction_loss'])\n",
        "        plt.plot(history.history['val_kl_loss'])\n",
        "        plt.title('Model loss')\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('loss')\n",
        "        plt.legend(['loss','reconstruction_loss','kl_loss','val_loss','val_reconstruction_loss','val_kl_loss'],loc = 'upper left')\n",
        "showloss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdx2QdjrZfff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model prediction \n",
        "train_vae_prediction = vae.predict(X_train,verbose = 1)\n",
        "valid_vae_prediction = vae.predict(X_valid , verbose = 1)\n",
        "test_vae_prediction = vae.predict(X_test , verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWupqB2jZffl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_vae_prediction.shape)\n",
        "print(valid_vae_prediction.shape)\n",
        "print(test_vae_prediction.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJUGng1lZffr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image visualization\n",
        "def visualizer(data , model):\n",
        "    n=10\n",
        "#     images = next(iter(data))[0]\n",
        "    images = data[:20]\n",
        "    predictions = model.predict(images)\n",
        "    print(predictions.shape)\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        orig = images[i,:,:,:].reshape(128,128,3)\n",
        "        orig = (orig +1)/2\n",
        "        plt.imshow((255*orig).astype('uint8').squeeze() ,cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        pred = predictions[i,:,:,:].reshape(128,128,3)\n",
        "        pred = (pred + 1)/2\n",
        "        plt.imshow((255*pred).astype('uint8').squeeze(),cmap='gray')\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk2YwjTlZffx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualizer(X_train , vae)\n",
        "visualizer(X_valid , vae)\n",
        "visualizer(X_test , vae)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}