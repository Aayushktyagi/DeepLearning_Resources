{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.transform import rescale, resize\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING THE DATA INTO A NUMPY ARRAY\n",
    "\n",
    "x_data_train = []\n",
    "x_data_train_path = []\n",
    "for png in tqdm(os.listdir('Dataset/Compaq_orignal/train/images/1')):\n",
    "    path = 'Dataset/Compaq_orignal/train/images/1/{}'.format(png)\n",
    "    x_data_train_path.append(path)\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image,(256,256))\n",
    "    image = image / 255.\n",
    "#     image = image.astype('float32')\n",
    "    x_data_train.append(image)\n",
    "    \n",
    "x_data_train = np.array(x_data_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_test = []\n",
    "x_data_test_path = []\n",
    "for png in tqdm(os.listdir('Dataset/Compaq_orignal/test/images/1')):\n",
    "    path = 'Dataset/Compaq_orignal/test/images/1/{}'.format(png)\n",
    "    x_data_test_path.append(path)\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image,(256,256))\n",
    "    image = image / 255.\n",
    "#     image = image.astype('float32')\n",
    "    x_data_test.append(image)\n",
    "    \n",
    "x_data_test = np.array(x_data_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data_test = x_data_train[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_data_train[89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KERAS IMPORTS\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "# from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "from tensorflow.keras.layers import Add, Multiply\n",
    "\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET A SEED FOR REPRODUCABILITY\n",
    "np.random.seed(20)\n",
    "\n",
    "#NUMBER OF DIMENSIONS IN THE ENCODED LAYER\n",
    "latent_dims = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODER\n",
    "#BUILT WITH FUNCTIONAL MODEL DUE TO THE MULTIPLE INPUTS AND OUTPUTS\n",
    "\n",
    "encoder_in = Input(shape=(256,256,3))   ##INPUT FOR THE IMAGE\n",
    "\n",
    "encoder_l1 = Conv2D(filters=32, kernel_size=5, strides=1, padding='same', input_shape=(256,256,3))(encoder_in)\n",
    "encoder_l1 = BatchNormalization()(encoder_l1)\n",
    "encoder_l1 = Activation(LeakyReLU(0.2))(encoder_l1)\n",
    "\n",
    "encoder_l1 = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(encoder_l1)\n",
    "encoder_l1 = BatchNormalization()(encoder_l1)\n",
    "encoder_l1 = Activation(LeakyReLU(0.2))(encoder_l1)\n",
    "\n",
    "\n",
    "encoder_l2 = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(encoder_l1)\n",
    "encoder_l2 = BatchNormalization()(encoder_l2)\n",
    "encoder_l2 = Activation(LeakyReLU(0.2))(encoder_l2)\n",
    "\n",
    "encoder_l3 = Conv2D(filters=256, kernel_size=5, strides=2, padding='same')(encoder_l2)\n",
    "encoder_l3 = BatchNormalization()(encoder_l3)\n",
    "encoder_l3 = Activation(LeakyReLU(0.2))(encoder_l3)\n",
    "\n",
    "\n",
    "encoder_l4 = Conv2D(filters=512, kernel_size=5, strides=2, padding='same')(encoder_l3)\n",
    "encoder_l4 = BatchNormalization()(encoder_l4)\n",
    "encoder_l4 = Activation(LeakyReLU(0.2))(encoder_l4)\n",
    "\n",
    "flatten = Flatten()(encoder_l4)\n",
    "\n",
    "encoder_dense = Dense(1024)(flatten)\n",
    "encoder_dense = BatchNormalization()(encoder_dense)\n",
    "encoder_out = Activation(LeakyReLU(0.2))(encoder_dense)\n",
    "\n",
    "\n",
    "mu = Dense(latent_dims)(encoder_out)\n",
    "log_var = Dense(latent_dims)(encoder_out)\n",
    "\n",
    "\n",
    "epsilon = Input(tensor=K.random_normal(shape=(K.shape(mu)[0], latent_dims)))  ##INPUT EPSILON FOR RANDOM SAMPLING\n",
    "\n",
    "sigma = Lambda(lambda x: K.exp(0.5 * x))(log_var) # CHANGE log_var INTO STANDARD DEVIATION(sigma)\n",
    "z_eps = Multiply()([sigma, epsilon])\n",
    "\n",
    "z = Add()([mu, z_eps])\n",
    "\n",
    "encoder=Model([encoder_in,epsilon], z)\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER\n",
    "# BUILT WITH SEQUENTIAL MODEL AS NO BRANCHING IS REQUIRED\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(1024, input_shape=(latent_dims,)))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Dense(8192))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Reshape(target_shape=(4,4,512)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=256, kernel_size=5, strides=2, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=32, kernel_size=5, strides=2, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=16, kernel_size=5, strides=2, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=8, kernel_size=5, strides=2, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation(LeakyReLU(0.2)))\n",
    "\n",
    "decoder.add(Conv2DTranspose(filters=3, kernel_size=5, strides=1, padding='same'))\n",
    "decoder.add(BatchNormalization())\n",
    "decoder.add(Activation('sigmoid'))\n",
    "\n",
    "print(decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE ENCODER AND DECODER THE COMPLETE THE VARIATIONAL AUTO ENCODER\n",
    "\n",
    "vae_preds = decoder(z)\n",
    "vae = Model([encoder_in, epsilon], vae_preds)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MY LOSS FUNCTIONS\n",
    "\n",
    "def reconstruction_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred))\n",
    "\n",
    "def kl_loss(y_true, y_pred):\n",
    "    kl_loss = - 0.5 * K.mean(1 + log_var - K.square(mu) - K.exp(log_var), axis=-1)\n",
    "    return kl_loss\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "#     return reconstruction_loss(y_true, y_pred) + 0.03 * kl_loss(y_true, y_pred)   #scaling kl_loss by 0.03 seem to help\n",
    "    return reconstruction_loss(y_true, y_pred) + 0.5 * kl_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl_annealtime = 20\n",
    "\n",
    "# class AnnealingCallback(Callback):\n",
    "#     def __init__(self, weight):\n",
    "#         self.weight = weight\n",
    "#     def on_epoch_end (self, epoch, logs={}):\n",
    "#         if epoch > klstart :\n",
    "#             new_weight = min(K.get_value(self.weight) + (1./ annealtime), 1.)\n",
    "#             K.set_value(self.weight, new_weight)\n",
    "#         print (\"Current KL Weight is \" + str(K.get_value(self.weight)))\n",
    "\n",
    "\n",
    "# # the starting value of weight is 0\n",
    "# # define it as a keras backend variable\n",
    "# weight = K.variable(0.)\n",
    "# # wrap the loss as a function of weight\n",
    "# def vae_loss(weight):\n",
    "#     def loss (y_true, y_pred):\n",
    "#         # mse loss\n",
    "#         reconstruction_loss = K.sum(K.square(y_true - y_pred), axis=-1)\n",
    "#         # kl loss\n",
    "#         kl_loss = 1 + log_var - K.square(mu) - K.exp(log_var)\n",
    "#         kl_loss = K.sum(kl_loss, axis=-1)\n",
    "#         kl_loss *= -0.5\n",
    "#         return reconstruction_loss + (weight * kl_loss)\n",
    "#     return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.compile(optimizer='adam', loss=vae_loss , metrics=[reconstruction_loss, kl_loss])\n",
    "vae.compile(optimizer='adam', loss=vae_loss , metrics=[reconstruction_loss,kl_loss])\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1,monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor = 'val_loss',factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('./models/vae_skin_keras/vae_b16/vae_oCompq_norm_kl0d5_l256.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=vae.fit(x_data_train,x_data_train,\n",
    "                epochs=150,\n",
    "                batch_size=16,\n",
    "                validation_data = (x_data_test,x_data_test),\n",
    "               callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showloss(history):\n",
    "        # loss plot\n",
    "        plt.subplots(figsize=(15,10))\n",
    "        plt.subplot(1,1,1)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['reconstruction_loss'])\n",
    "        plt.plot(history.history['kl_loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.plot(history.history['val_reconstruction_loss'])\n",
    "        plt.plot(history.history['val_kl_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend(['loss','reconstruction_loss','kl_loss','val_loss','val_reconstruction_loss','val_kl_loss'],loc = 'upper left')\n",
    "\n",
    "\n",
    "\n",
    "showloss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights('./models/vae_skin_keras/vae_b16/vae_oCompq_norm_kl0d5_l256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL IMAGES\n",
    "x_data_test = x_data_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructed images\n",
    "predictions  = vae.predict(x_data_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_data_test[i].reshape(256, 256,3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(predictions[i].reshape(256, 256,3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_images(path,predictions):\n",
    "#     print(len(predictions))\n",
    "#     for index,image in enumerate(predictions):\n",
    "#         cv2.write(\"./Reconstructed/Test_reconstructions/Reconstructed_images_{}.png\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
